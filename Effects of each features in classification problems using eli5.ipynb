{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far I have been checking [eli5][1] and [treeinterpreter][2] (both have been mentioned before) and I think eli5 will be the most helpfull, because I think have more options and is more generic and updated.\n",
    "\n",
    "\n",
    "\n",
    "Nevertheless after some time I apply eli5 for a particular case and I could not obtained negative contributions for [ExtraTreesClassifier][3] researching a little bit more I realised I was obtaining the importance or weight as seen [here][4]. Because I was more interested in something like contribution, as mentioned of the title of this questions, I understand some feature could have a negative effect but when measuring the importance the sign is not important, so feature with positive effects and negatives are put together.\n",
    "\n",
    "Because I was very interested in the sign I did as follows:\n",
    "1) obtain the contributions for all cases\n",
    "2) agreage all the results to be able to distinguish the same.\n",
    "No very elegant solution, probably there is something better out there, I post it here in case it helps.\n",
    "\n",
    "I reproduce the same that [previous post][5].\n",
    "\n",
    "  [1]: http://eli5.readthedocs.io/en/latest/overview.html\n",
    "  [2]: https://github.com/andosa/treeinterpreter\n",
    "  [3]: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html\n",
    "  [4]: http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "  [5]: https://stackoverflow.com/a/35255612/7127519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import  (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier)\n",
    "import eli5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()  #sample data\n",
    "X, y = iris.data, iris.target\n",
    "#split into training and test \n",
    "X_train, X_test, y_train, y_test = train_test_split( \n",
    "    X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# fit the model on the training set\n",
    "#model = DecisionTreeClassifier(random_state=0)\n",
    "model = ExtraTreesClassifier(n_estimators= 100)\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0,\n",
       "       0, 1, 0, 2, 1, 0, 1, 2, 1, 0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2,\n",
       "       0, 0, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0,\n",
       "       2, 0, 2, 0, 0, 2, 0, 2, 1, 1, 1, 2, 2, 1, 1, 0, 1, 2, 2, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.4479\n",
       "                \n",
       "                    &plusmn; 0.4980\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.3920\n",
       "                \n",
       "                    &plusmn; 0.4878\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x2\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0968\n",
       "                \n",
       "                    &plusmn; 0.2311\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.92%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0633\n",
       "                \n",
       "                    &plusmn; 0.1422\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the weight. As you can see they are positive. So they looks like they only can be positive.\n",
    "eli5.show_weights(model, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 3 (0.474509)\n",
      "2. feature 2 (0.373542)\n",
      "3. feature 0 (0.098248)\n",
      "4. feature 1 (0.053701)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d14ec2860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# So I investigate I little bit more and check how those weight are effective calculated :\n",
    "#http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html \n",
    "\n",
    "forest = model \n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous results only can be positive. But I want the effect / contribution of each variable an it can be negative.\n",
    "Searching a little bit in eli5 I see there is the possibility to find those result for particular cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;BIAS&gt;</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>x3</td>\n",
       "      <td>0.285764</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>x2</td>\n",
       "      <td>0.267080</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>x1</td>\n",
       "      <td>0.058208</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>x0</td>\n",
       "      <td>0.048949</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;BIAS&gt;</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>x0</td>\n",
       "      <td>-0.004606</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>x1</td>\n",
       "      <td>-0.048211</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>x2</td>\n",
       "      <td>-0.111974</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>x3</td>\n",
       "      <td>-0.145209</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>&lt;BIAS&gt;</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>x1</td>\n",
       "      <td>-0.009997</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>x0</td>\n",
       "      <td>-0.044343</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>x3</td>\n",
       "      <td>-0.140554</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>x2</td>\n",
       "      <td>-0.155106</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target feature    weight  value\n",
       "0        0  <BIAS>  0.340000    1.0\n",
       "1        0      x3  0.285764    0.2\n",
       "2        0      x2  0.267080    1.4\n",
       "3        0      x1  0.058208    3.5\n",
       "4        0      x0  0.048949    5.1\n",
       "5        1  <BIAS>  0.310000    1.0\n",
       "6        1      x0 -0.004606    5.1\n",
       "7        1      x1 -0.048211    3.5\n",
       "8        1      x2 -0.111974    1.4\n",
       "9        1      x3 -0.145209    0.2\n",
       "10       2  <BIAS>  0.350000    1.0\n",
       "11       2      x1 -0.009997    3.5\n",
       "12       2      x0 -0.044343    5.1\n",
       "13       2      x3 -0.140554    0.2\n",
       "14       2      x2 -0.155106    1.4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "aux1 = eli5.sklearn.explain_prediction.explain_prediction_tree_classifier(model,X[0], top=X.shape[0])\n",
    "aux1 = eli5.format_as_dataframe(aux1)\n",
    "# aux1.index = aux1['feature']\n",
    "# del aux1['target']\n",
    "aux1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want that but in my whole population. That will help me to understand the average effect or contribution of \n",
    "each variable / feature alone.\n",
    "\n",
    "So I create a function to combine previous kind of tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">&lt;BIAS&gt;</th>\n",
       "      <th>0</th>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">x0</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.016759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">x1</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.006055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">x2</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.165008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.176310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.341318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">x3</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.152178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.111858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.264036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  weight\n",
       "feature target          \n",
       "<BIAS>  0       0.340000\n",
       "        1       0.310000\n",
       "        2       0.350000\n",
       "x0      0      -0.016759\n",
       "        1       0.016727\n",
       "        2       0.000031\n",
       "x1      0      -0.006055\n",
       "        1      -0.038560\n",
       "        2       0.044615\n",
       "x2      0      -0.165008\n",
       "        1      -0.176310\n",
       "        2       0.341318\n",
       "x3      0      -0.152178\n",
       "        1      -0.111858\n",
       "        2       0.264036"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_average_dfs(aux2,aux3):\n",
    "    # Putting the same index together\n",
    "#     I use the try because I want to use this function recursive and \n",
    "#     I could potentially introduce dataframe with those indexes. This\n",
    "#     is not the best way.\n",
    "    try:\n",
    "        aux2.set_index(['feature', 'target'],inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        aux3.set_index(['feature', 'target'],inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "    # Concatenating and creating the meand\n",
    "    aux = pd.DataFrame(pd.concat([aux2['weight'],aux3['weight']]).groupby(level = [0,1]).mean())\n",
    "    # Return in order\n",
    "    #return aux.sort_values(['weight'],ascending = [False],inplace = True)\n",
    "    return aux\n",
    "aux2 = aux1.copy(deep=True)\n",
    "aux3 = aux1.copy(deep=True)\n",
    "\n",
    "concat_average_dfs(aux3,aux2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 150)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I only have to use previous function with all the examples I wish. I will take the whole population not only the training set. Check the average effect in all real cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">&lt;BIAS&gt;</th>\n",
       "      <th>0</th>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">x0</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.027712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">x1</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.001759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.023142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">x2</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.156598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.129817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.286415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">x3</th>\n",
       "      <th>0</th>\n",
       "      <td>-0.153931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.167408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.321339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  weight\n",
       "feature target          \n",
       "<BIAS>  0       0.340000\n",
       "        1       0.310000\n",
       "        2       0.350000\n",
       "x0      0      -0.027712\n",
       "        1       0.010482\n",
       "        2       0.017230\n",
       "x1      0      -0.001759\n",
       "        1      -0.023142\n",
       "        2       0.024901\n",
       "x2      0      -0.156598\n",
       "        1      -0.129817\n",
       "        2       0.286415\n",
       "x3      0      -0.153931\n",
       "        1      -0.167408\n",
       "        2       0.321339"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the average effect in all real cases\n",
    "for i in range(X.shape[0]):\n",
    "\n",
    "    \n",
    "    aux1 = eli5.sklearn.explain_prediction.explain_prediction_tree_classifier(model,X[i], top=X.shape[0])\n",
    "    aux1 = eli5.format_as_dataframe(aux1)\n",
    "    \n",
    "    if 'aux_total'  in locals() and 'aux_total' in  globals():\n",
    "        aux_total = concat_average_dfs(aux1,aux_total)\n",
    "    else:\n",
    "        aux_total = aux1\n",
    "aux_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Las table show the average effects of each feature for all my real population.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
